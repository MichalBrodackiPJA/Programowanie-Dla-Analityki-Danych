{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"8B3Tbf6UnH7q"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"markdown","metadata":{"id":"jj4cqcDOLYqN"},"source":["# Data Cleaning\n","\n","Przed uruchomieniem naszych danych przez model ważnym krokiem jest **Eksploracyjna analiza danych** lub EDA. EDA, jak sama nazwa wskazuje, to dogłębna analiza naszych danych. Proces EDA przeplata czyszczenie danych, radzenie sobie z brakującymi wartościami oraz wizualizację danych i ich właściwości statystycznych. Zazwyczaj wszystkie te procesy są wykonywane razem, ale dla potrzeb edukacyjnych rozbijemy je na osobne części.\n","\n","### Prerequisites\n","[flights.txt](https://drive.google.com/file/d/1cVV3TZcxS31fk9JrskaRP1pbOfaoNcwe/view?usp=sharing)\n","(źródło: https://www.kaggle.com/mmetter/flights/data).\n","W większości przypadków dane posiadają dokumentację. **Czytanie dokumentacji danych jest ważne**!!!! Ta konkretna część danych nie ma jednak żadnej dokumentacji - będziemy musieli skorzystać z naszej intuicji oraz nazw kolumn (zmiennych).\n","\n","### Typy danych\n","\n","<table >\n","\t<tbody>\n","\t\t<tr>\n","            <td><b>Typ danych</b></td>\n","            <td><b>Typ danych w Pythonie</b></td>\n","            <td><b>Przykłady</b></td>\n","\t\t</tr>\n","\t\t<tr>\n","\t\t\t<td>Dane tekstowe</td>\n","            <td>str</td>\n","\t\t\t<td>Nazwiska, adresy</td>\n","\t\t</tr>\n","\t\t<tr>\n","\t\t\t<td>Integers</td>\n","            <td>int</td>\n","\t\t\t<td># przedmioty, # osoby</td>\n","\t\t</tr>\n","\t\t<tr>\n","\t\t\t<td>Floats/Ułamki</td>\n","            <td>float</td>\n","\t\t\t<td>Waluty, odległości</td>\n","\t\t</tr>\n","\t\t<tr>\n","\t\t\t<td>Binary/Boolean</td>\n","            <td>bool</td>\n","\t\t\t<td>Pytania zamknięte, yes/no</td>\n","\t\t</tr>\n","\t\t<tr>\n","\t\t\t<td>Data (i czas)</td>\n","            <td>datetime</td>\n","\t\t\t<td>Data wysyłki, czas przyjazdu</td>\n","\t\t</tr>\n","\t\t<tr>\n","\t\t\t<td>Kategorie</td>\n","            <td>category</td>\n","\t\t\t<td>Stany, kolory, płeć</td>\n","\t\t</tr>\n","\t</tbody>\n","</table>"]},{"cell_type":"code","execution_count":1,"metadata":{"id":"jxH6Py-e1Qzx"},"outputs":[],"source":["path='flights.txt'"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"OqdQSm72LYqg"},"outputs":[],"source":["import pandas as pd\n","pd.set_option('display.max_columns', None)\n","flights_df = pd.read_csv(\"flights.txt\", sep=\"|\")"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"EKCaICraLYql","scrolled":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>TRANSACTIONID</th>\n","      <th>FLIGHTDATE</th>\n","      <th>AIRLINECODE</th>\n","      <th>AIRLINENAME</th>\n","      <th>TAILNUM</th>\n","      <th>FLIGHTNUM</th>\n","      <th>ORIGINAIRPORTCODE</th>\n","      <th>ORIGAIRPORTNAME</th>\n","      <th>ORIGINCITYNAME</th>\n","      <th>ORIGINSTATE</th>\n","      <th>ORIGINSTATENAME</th>\n","      <th>DESTAIRPORTCODE</th>\n","      <th>DESTAIRPORTNAME</th>\n","      <th>DESTCITYNAME</th>\n","      <th>DESTSTATE</th>\n","      <th>DESTSTATENAME</th>\n","      <th>CRSDEPTIME</th>\n","      <th>DEPTIME</th>\n","      <th>DEPDELAY</th>\n","      <th>TAXIOUT</th>\n","      <th>WHEELSOFF</th>\n","      <th>WHEELSON</th>\n","      <th>TAXIIN</th>\n","      <th>CRSARRTIME</th>\n","      <th>ARRTIME</th>\n","      <th>ARRDELAY</th>\n","      <th>CRSELAPSEDTIME</th>\n","      <th>ACTUALELAPSEDTIME</th>\n","      <th>CANCELLED</th>\n","      <th>DIVERTED</th>\n","      <th>DISTANCE</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>54548800</td>\n","      <td>20020101</td>\n","      <td>WN</td>\n","      <td>Southwest Airlines Co.: WN</td>\n","      <td>N103@@</td>\n","      <td>1425</td>\n","      <td>ABQ</td>\n","      <td>AlbuquerqueNM: Albuquerque International Sunport</td>\n","      <td>Albuquerque</td>\n","      <td>NM</td>\n","      <td>New Mexico</td>\n","      <td>DAL</td>\n","      <td>DallasTX: Dallas Love Field</td>\n","      <td>Dallas</td>\n","      <td>TX</td>\n","      <td>Texas</td>\n","      <td>1425</td>\n","      <td>1425.0</td>\n","      <td>0.0</td>\n","      <td>8.0</td>\n","      <td>1433.0</td>\n","      <td>1648.0</td>\n","      <td>4.0</td>\n","      <td>1655</td>\n","      <td>1652.0</td>\n","      <td>-3.0</td>\n","      <td>90.0</td>\n","      <td>87.0</td>\n","      <td>F</td>\n","      <td>False</td>\n","      <td>580 miles</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>55872300</td>\n","      <td>20020101</td>\n","      <td>CO</td>\n","      <td>Continental Air Lines Inc.: CO</td>\n","      <td>N83872</td>\n","      <td>150</td>\n","      <td>ABQ</td>\n","      <td>AlbuquerqueNM: Albuquerque International Sunport</td>\n","      <td>Albuquerque</td>\n","      <td>NM</td>\n","      <td>New Mexico</td>\n","      <td>IAH</td>\n","      <td>HoustonTX: George Bush Intercontinental/Houston</td>\n","      <td>Houston</td>\n","      <td>TX</td>\n","      <td>Texas</td>\n","      <td>1130</td>\n","      <td>1136.0</td>\n","      <td>6.0</td>\n","      <td>12.0</td>\n","      <td>1148.0</td>\n","      <td>1419.0</td>\n","      <td>16.0</td>\n","      <td>1426</td>\n","      <td>1435.0</td>\n","      <td>9.0</td>\n","      <td>116.0</td>\n","      <td>119.0</td>\n","      <td>False</td>\n","      <td>F</td>\n","      <td>744 miles</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>54388800</td>\n","      <td>20020101</td>\n","      <td>WN</td>\n","      <td>Southwest Airlines Co.: WN</td>\n","      <td>N334@@</td>\n","      <td>249</td>\n","      <td>ABQ</td>\n","      <td>AlbuquerqueNM: Albuquerque International Sunport</td>\n","      <td>Albuquerque</td>\n","      <td>NM</td>\n","      <td>New Mexico</td>\n","      <td>MCI</td>\n","      <td>Kansas CityMO: Kansas City International</td>\n","      <td>Kansas City</td>\n","      <td>MO</td>\n","      <td>Missouri</td>\n","      <td>1215</td>\n","      <td>1338.0</td>\n","      <td>83.0</td>\n","      <td>7.0</td>\n","      <td>1345.0</td>\n","      <td>1618.0</td>\n","      <td>2.0</td>\n","      <td>1500</td>\n","      <td>1620.0</td>\n","      <td>80.0</td>\n","      <td>105.0</td>\n","      <td>102.0</td>\n","      <td>F</td>\n","      <td>False</td>\n","      <td>718 miles</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>54486500</td>\n","      <td>20020101</td>\n","      <td>WN</td>\n","      <td>Southwest Airlines Co.: WN</td>\n","      <td>N699@@</td>\n","      <td>902</td>\n","      <td>ABQ</td>\n","      <td>AlbuquerqueNM: Albuquerque International Sunport</td>\n","      <td>Albuquerque</td>\n","      <td>NM</td>\n","      <td>New Mexico</td>\n","      <td>LAS</td>\n","      <td>Las VegasNV: McCarran International</td>\n","      <td>Las Vegas</td>\n","      <td>NV</td>\n","      <td>Nevada</td>\n","      <td>1925</td>\n","      <td>1925.0</td>\n","      <td>0.0</td>\n","      <td>5.0</td>\n","      <td>1930.0</td>\n","      <td>1947.0</td>\n","      <td>1.0</td>\n","      <td>1950</td>\n","      <td>1948.0</td>\n","      <td>-2.0</td>\n","      <td>85.0</td>\n","      <td>83.0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>487 miles</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>55878700</td>\n","      <td>20020103</td>\n","      <td>CO</td>\n","      <td>Continental Air Lines Inc.: CO</td>\n","      <td>N58606</td>\n","      <td>234</td>\n","      <td>ABQ</td>\n","      <td>AlbuquerqueNM: Albuquerque International Sunport</td>\n","      <td>Albuquerque</td>\n","      <td>NM</td>\n","      <td>New Mexico</td>\n","      <td>IAH</td>\n","      <td>HoustonTX: George Bush Intercontinental/Houston</td>\n","      <td>Houston</td>\n","      <td>TX</td>\n","      <td>Texas</td>\n","      <td>1455</td>\n","      <td>1453.0</td>\n","      <td>-2.0</td>\n","      <td>11.0</td>\n","      <td>1504.0</td>\n","      <td>1742.0</td>\n","      <td>5.0</td>\n","      <td>1750</td>\n","      <td>1747.0</td>\n","      <td>-3.0</td>\n","      <td>115.0</td>\n","      <td>114.0</td>\n","      <td>F</td>\n","      <td>False</td>\n","      <td>744 miles</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   TRANSACTIONID  FLIGHTDATE AIRLINECODE                     AIRLINENAME  \\\n","0       54548800    20020101          WN      Southwest Airlines Co.: WN   \n","1       55872300    20020101          CO  Continental Air Lines Inc.: CO   \n","2       54388800    20020101          WN      Southwest Airlines Co.: WN   \n","3       54486500    20020101          WN      Southwest Airlines Co.: WN   \n","4       55878700    20020103          CO  Continental Air Lines Inc.: CO   \n","\n","  TAILNUM  FLIGHTNUM ORIGINAIRPORTCODE  \\\n","0  N103@@       1425               ABQ   \n","1  N83872        150               ABQ   \n","2  N334@@        249               ABQ   \n","3  N699@@        902               ABQ   \n","4  N58606        234               ABQ   \n","\n","                                    ORIGAIRPORTNAME ORIGINCITYNAME  \\\n","0  AlbuquerqueNM: Albuquerque International Sunport    Albuquerque   \n","1  AlbuquerqueNM: Albuquerque International Sunport    Albuquerque   \n","2  AlbuquerqueNM: Albuquerque International Sunport    Albuquerque   \n","3  AlbuquerqueNM: Albuquerque International Sunport    Albuquerque   \n","4  AlbuquerqueNM: Albuquerque International Sunport    Albuquerque   \n","\n","  ORIGINSTATE ORIGINSTATENAME DESTAIRPORTCODE  \\\n","0          NM      New Mexico             DAL   \n","1          NM      New Mexico             IAH   \n","2          NM      New Mexico             MCI   \n","3          NM      New Mexico             LAS   \n","4          NM      New Mexico             IAH   \n","\n","                                   DESTAIRPORTNAME DESTCITYNAME DESTSTATE  \\\n","0                      DallasTX: Dallas Love Field       Dallas        TX   \n","1  HoustonTX: George Bush Intercontinental/Houston      Houston        TX   \n","2         Kansas CityMO: Kansas City International  Kansas City        MO   \n","3              Las VegasNV: McCarran International    Las Vegas        NV   \n","4  HoustonTX: George Bush Intercontinental/Houston      Houston        TX   \n","\n","  DESTSTATENAME  CRSDEPTIME  DEPTIME  DEPDELAY  TAXIOUT  WHEELSOFF  WHEELSON  \\\n","0         Texas        1425   1425.0       0.0      8.0     1433.0    1648.0   \n","1         Texas        1130   1136.0       6.0     12.0     1148.0    1419.0   \n","2      Missouri        1215   1338.0      83.0      7.0     1345.0    1618.0   \n","3        Nevada        1925   1925.0       0.0      5.0     1930.0    1947.0   \n","4         Texas        1455   1453.0      -2.0     11.0     1504.0    1742.0   \n","\n","   TAXIIN  CRSARRTIME  ARRTIME  ARRDELAY  CRSELAPSEDTIME  ACTUALELAPSEDTIME  \\\n","0     4.0        1655   1652.0      -3.0            90.0               87.0   \n","1    16.0        1426   1435.0       9.0           116.0              119.0   \n","2     2.0        1500   1620.0      80.0           105.0              102.0   \n","3     1.0        1950   1948.0      -2.0            85.0               83.0   \n","4     5.0        1750   1747.0      -3.0           115.0              114.0   \n","\n","  CANCELLED DIVERTED   DISTANCE  \n","0         F    False  580 miles  \n","1     False        F  744 miles  \n","2         F    False  718 miles  \n","3         0        0  487 miles  \n","4         F    False  744 miles  "]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["flights_df.head()"]},{"cell_type":"markdown","metadata":{"id":"Ep16wLemLYqp"},"source":["Zestaw danych flights jest problematyzny z wielu względów, ale zanim na nie odpowiemy, przyjrzymy się nazwom zmiennych."]},{"cell_type":"markdown","metadata":{"id":"vxcZaN6-LYqs"},"source":["- **TRANSACTIONID**: Unikalny identyfikator\n","\n","- **FLIGHTDATE**: Data lotu. Wygląda na to, że jest zakodowana jako liczba zamiast obiektu daty\n","\n","- **TAILNUM**: Wygląda na to, że w niektórych wierszach zawiera @@ \n","\n","- **ORIGAIRPORTNAME** oraz **DESTAIRPORTNAME**: Wygląda na to, że nazwa miasta i stan są połączone i dołączone przed rzeczywistą nazwą lotniska \n","\n","- **CRSDEPTIME** oraz **DEPTIME**: Wygląda na to, że zawierają niepoprawnie sformatowane czasy. Wydaje się też, że: **CRSDEPTTIME** + **DEPDELAY** = **DEPTIME**\n","\n","- **DEPDELAY**: Opóźnienie wyjazdu w minutach?\n","\n","- **TAXIOUT**: Ile czasu upłynęło od wystartowania silnika do oderwania się od ziemi? Poza tym: **DEPTIME** + **TAXIOUT** = **WHEELSOFF**\n","\n","- **WHEELSOFF**: Czas, w którym koła oderwały się od ziemi\n","\n","- **WHEELSON**: Czas, w którym koła dotknęły ziemi podczas lądowania\n","\n","- **TAXIIN**: Wygląda na liczbę minut od zetknięcia kół z ziemią do „parkowania”\n","\n","- **CRSARRTIME**: Oczekiwany czas przylotu w formacie 24h\n","\n","- **ARRTIME**: Faktyczny czas przylotu \n","\n","- **ARRDELAY**: Różnica pomiędzy **CRSARRTIME** oraz **ARRTIME**\n","\n","- **CRSELAPSEDTIME**: Planowany czas podróży (minuty)\n","\n","- **ACTUALELAPSEDTIME**: Rzeczywisty czas podróży (minuty)\n","\n","- **CANCELLED**: Czy lot został odwołany czy nie. Niektóre wartości logiczne zostały przedstawione jako False, inne jako 0. Podobnie jest z wartościami True i 1.\n","\n","- **DIVERTED**: Czy samolot został przekierowany. Podobne problemy dotyczące True/False jak powyżej?\n","\n","- **DISTANCE**: Odległość (całkowita) przebyta przez samolot, zakodowana jako ciąg znaków z połączonymi z nim „milami” "]},{"cell_type":"code","execution_count":4,"metadata":{"id":"1Epxt7igLYqv"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>TRANSACTIONID</th>\n","      <th>FLIGHTDATE</th>\n","      <th>AIRLINECODE</th>\n","      <th>AIRLINENAME</th>\n","      <th>TAILNUM</th>\n","      <th>FLIGHTNUM</th>\n","      <th>ORIGINAIRPORTCODE</th>\n","      <th>ORIGAIRPORTNAME</th>\n","      <th>ORIGINCITYNAME</th>\n","      <th>ORIGINSTATE</th>\n","      <th>ORIGINSTATENAME</th>\n","      <th>DESTAIRPORTCODE</th>\n","      <th>DESTAIRPORTNAME</th>\n","      <th>DESTCITYNAME</th>\n","      <th>DESTSTATE</th>\n","      <th>DESTSTATENAME</th>\n","      <th>CRSDEPTIME</th>\n","      <th>DEPTIME</th>\n","      <th>DEPDELAY</th>\n","      <th>TAXIOUT</th>\n","      <th>WHEELSOFF</th>\n","      <th>WHEELSON</th>\n","      <th>TAXIIN</th>\n","      <th>CRSARRTIME</th>\n","      <th>ARRTIME</th>\n","      <th>ARRDELAY</th>\n","      <th>CRSELAPSEDTIME</th>\n","      <th>ACTUALELAPSEDTIME</th>\n","      <th>CANCELLED</th>\n","      <th>DIVERTED</th>\n","      <th>DISTANCE</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>54548800</td>\n","      <td>20020101</td>\n","      <td>WN</td>\n","      <td>Southwest Airlines Co.: WN</td>\n","      <td>N103@@</td>\n","      <td>1425</td>\n","      <td>ABQ</td>\n","      <td>AlbuquerqueNM: Albuquerque International Sunport</td>\n","      <td>Albuquerque</td>\n","      <td>NM</td>\n","      <td>New Mexico</td>\n","      <td>DAL</td>\n","      <td>DallasTX: Dallas Love Field</td>\n","      <td>Dallas</td>\n","      <td>TX</td>\n","      <td>Texas</td>\n","      <td>1425</td>\n","      <td>1425.0</td>\n","      <td>0.0</td>\n","      <td>8.0</td>\n","      <td>1433.0</td>\n","      <td>1648.0</td>\n","      <td>4.0</td>\n","      <td>1655</td>\n","      <td>1652.0</td>\n","      <td>-3.0</td>\n","      <td>90.0</td>\n","      <td>87.0</td>\n","      <td>F</td>\n","      <td>False</td>\n","      <td>580 miles</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>55872300</td>\n","      <td>20020101</td>\n","      <td>CO</td>\n","      <td>Continental Air Lines Inc.: CO</td>\n","      <td>N83872</td>\n","      <td>150</td>\n","      <td>ABQ</td>\n","      <td>AlbuquerqueNM: Albuquerque International Sunport</td>\n","      <td>Albuquerque</td>\n","      <td>NM</td>\n","      <td>New Mexico</td>\n","      <td>IAH</td>\n","      <td>HoustonTX: George Bush Intercontinental/Houston</td>\n","      <td>Houston</td>\n","      <td>TX</td>\n","      <td>Texas</td>\n","      <td>1130</td>\n","      <td>1136.0</td>\n","      <td>6.0</td>\n","      <td>12.0</td>\n","      <td>1148.0</td>\n","      <td>1419.0</td>\n","      <td>16.0</td>\n","      <td>1426</td>\n","      <td>1435.0</td>\n","      <td>9.0</td>\n","      <td>116.0</td>\n","      <td>119.0</td>\n","      <td>False</td>\n","      <td>F</td>\n","      <td>744 miles</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>54388800</td>\n","      <td>20020101</td>\n","      <td>WN</td>\n","      <td>Southwest Airlines Co.: WN</td>\n","      <td>N334@@</td>\n","      <td>249</td>\n","      <td>ABQ</td>\n","      <td>AlbuquerqueNM: Albuquerque International Sunport</td>\n","      <td>Albuquerque</td>\n","      <td>NM</td>\n","      <td>New Mexico</td>\n","      <td>MCI</td>\n","      <td>Kansas CityMO: Kansas City International</td>\n","      <td>Kansas City</td>\n","      <td>MO</td>\n","      <td>Missouri</td>\n","      <td>1215</td>\n","      <td>1338.0</td>\n","      <td>83.0</td>\n","      <td>7.0</td>\n","      <td>1345.0</td>\n","      <td>1618.0</td>\n","      <td>2.0</td>\n","      <td>1500</td>\n","      <td>1620.0</td>\n","      <td>80.0</td>\n","      <td>105.0</td>\n","      <td>102.0</td>\n","      <td>F</td>\n","      <td>False</td>\n","      <td>718 miles</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>54486500</td>\n","      <td>20020101</td>\n","      <td>WN</td>\n","      <td>Southwest Airlines Co.: WN</td>\n","      <td>N699@@</td>\n","      <td>902</td>\n","      <td>ABQ</td>\n","      <td>AlbuquerqueNM: Albuquerque International Sunport</td>\n","      <td>Albuquerque</td>\n","      <td>NM</td>\n","      <td>New Mexico</td>\n","      <td>LAS</td>\n","      <td>Las VegasNV: McCarran International</td>\n","      <td>Las Vegas</td>\n","      <td>NV</td>\n","      <td>Nevada</td>\n","      <td>1925</td>\n","      <td>1925.0</td>\n","      <td>0.0</td>\n","      <td>5.0</td>\n","      <td>1930.0</td>\n","      <td>1947.0</td>\n","      <td>1.0</td>\n","      <td>1950</td>\n","      <td>1948.0</td>\n","      <td>-2.0</td>\n","      <td>85.0</td>\n","      <td>83.0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>487 miles</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>55878700</td>\n","      <td>20020103</td>\n","      <td>CO</td>\n","      <td>Continental Air Lines Inc.: CO</td>\n","      <td>N58606</td>\n","      <td>234</td>\n","      <td>ABQ</td>\n","      <td>AlbuquerqueNM: Albuquerque International Sunport</td>\n","      <td>Albuquerque</td>\n","      <td>NM</td>\n","      <td>New Mexico</td>\n","      <td>IAH</td>\n","      <td>HoustonTX: George Bush Intercontinental/Houston</td>\n","      <td>Houston</td>\n","      <td>TX</td>\n","      <td>Texas</td>\n","      <td>1455</td>\n","      <td>1453.0</td>\n","      <td>-2.0</td>\n","      <td>11.0</td>\n","      <td>1504.0</td>\n","      <td>1742.0</td>\n","      <td>5.0</td>\n","      <td>1750</td>\n","      <td>1747.0</td>\n","      <td>-3.0</td>\n","      <td>115.0</td>\n","      <td>114.0</td>\n","      <td>F</td>\n","      <td>False</td>\n","      <td>744 miles</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>1191800</th>\n","      <td>126750200</td>\n","      <td>20130106</td>\n","      <td>EV</td>\n","      <td>ExpressJet Airlines Inc.: EV</td>\n","      <td>N683BR</td>\n","      <td>5272</td>\n","      <td>ATL</td>\n","      <td>AtlantaGA: Hartsfield-Jackson Atlanta Internat...</td>\n","      <td>Atlanta</td>\n","      <td>GA</td>\n","      <td>Georgia</td>\n","      <td>DAL</td>\n","      <td>DallasTX: Dallas Love Field</td>\n","      <td>Dallas</td>\n","      <td>TX</td>\n","      <td>Texas</td>\n","      <td>1357</td>\n","      <td>1348.0</td>\n","      <td>-9.0</td>\n","      <td>22.0</td>\n","      <td>1410.0</td>\n","      <td>1500.0</td>\n","      <td>3.0</td>\n","      <td>1523</td>\n","      <td>1503.0</td>\n","      <td>-20.0</td>\n","      <td>146.0</td>\n","      <td>135.0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>721 miles</td>\n","    </tr>\n","    <tr>\n","      <th>1191801</th>\n","      <td>127294500</td>\n","      <td>20130106</td>\n","      <td>DL</td>\n","      <td>Delta Air Lines Inc.: DL</td>\n","      <td>N949DL</td>\n","      <td>1711</td>\n","      <td>ATL</td>\n","      <td>AtlantaGA: Hartsfield-Jackson Atlanta Internat...</td>\n","      <td>Atlanta</td>\n","      <td>GA</td>\n","      <td>Georgia</td>\n","      <td>DFW</td>\n","      <td>Dallas/Fort WorthTX: Dallas/Fort Worth Interna...</td>\n","      <td>Dallas/Fort Worth</td>\n","      <td>TX</td>\n","      <td>Texas</td>\n","      <td>2150</td>\n","      <td>2147.0</td>\n","      <td>-3.0</td>\n","      <td>23.0</td>\n","      <td>2210.0</td>\n","      <td>2307.0</td>\n","      <td>10.0</td>\n","      <td>2321</td>\n","      <td>2317.0</td>\n","      <td>-4.0</td>\n","      <td>151.0</td>\n","      <td>150.0</td>\n","      <td>False</td>\n","      <td>F</td>\n","      <td>731 miles</td>\n","    </tr>\n","    <tr>\n","      <th>1191802</th>\n","      <td>127294900</td>\n","      <td>20130106</td>\n","      <td>DL</td>\n","      <td>Delta Air Lines Inc.: DL</td>\n","      <td>N907DE</td>\n","      <td>1810</td>\n","      <td>ATL</td>\n","      <td>AtlantaGA: Hartsfield-Jackson Atlanta Internat...</td>\n","      <td>Atlanta</td>\n","      <td>GA</td>\n","      <td>Georgia</td>\n","      <td>DFW</td>\n","      <td>Dallas/Fort WorthTX: Dallas/Fort Worth Interna...</td>\n","      <td>Dallas/Fort Worth</td>\n","      <td>TX</td>\n","      <td>Texas</td>\n","      <td>1617</td>\n","      <td>1617.0</td>\n","      <td>0.0</td>\n","      <td>18.0</td>\n","      <td>1635.0</td>\n","      <td>1728.0</td>\n","      <td>9.0</td>\n","      <td>1750</td>\n","      <td>1737.0</td>\n","      <td>-13.0</td>\n","      <td>153.0</td>\n","      <td>140.0</td>\n","      <td>F</td>\n","      <td>False</td>\n","      <td>731 miles</td>\n","    </tr>\n","    <tr>\n","      <th>1191803</th>\n","      <td>126594900</td>\n","      <td>20130106</td>\n","      <td>EV</td>\n","      <td>ExpressJet Airlines Inc.: EV</td>\n","      <td>N855AS</td>\n","      <td>5208</td>\n","      <td>ATL</td>\n","      <td>AtlantaGA: Hartsfield-Jackson Atlanta Internat...</td>\n","      <td>Atlanta</td>\n","      <td>GA</td>\n","      <td>Georgia</td>\n","      <td>FWA</td>\n","      <td>Fort WayneIN: Fort Wayne International</td>\n","      <td>Fort Wayne</td>\n","      <td>IN</td>\n","      <td>Indiana</td>\n","      <td>1516</td>\n","      <td>1514.0</td>\n","      <td>-2.0</td>\n","      <td>21.0</td>\n","      <td>1535.0</td>\n","      <td>1651.0</td>\n","      <td>4.0</td>\n","      <td>1658</td>\n","      <td>1655.0</td>\n","      <td>-3.0</td>\n","      <td>102.0</td>\n","      <td>101.0</td>\n","      <td>False</td>\n","      <td>F</td>\n","      <td>508 miles</td>\n","    </tr>\n","    <tr>\n","      <th>1191804</th>\n","      <td>126620300</td>\n","      <td>20130106</td>\n","      <td>EV</td>\n","      <td>ExpressJet Airlines Inc.: EV</td>\n","      <td>N138EV</td>\n","      <td>5549</td>\n","      <td>ATL</td>\n","      <td>AtlantaGA: Hartsfield-Jackson Atlanta Internat...</td>\n","      <td>Atlanta</td>\n","      <td>GA</td>\n","      <td>Georgia</td>\n","      <td>GSO</td>\n","      <td>Greensboro/High PointNC: Piedmont Triad Intern...</td>\n","      <td>Greensboro/High Point</td>\n","      <td>NC</td>\n","      <td>North Carolina</td>\n","      <td>1452</td>\n","      <td>1458.0</td>\n","      <td>6.0</td>\n","      <td>27.0</td>\n","      <td>1525.0</td>\n","      <td>1611.0</td>\n","      <td>4.0</td>\n","      <td>1609</td>\n","      <td>1615.0</td>\n","      <td>6.0</td>\n","      <td>77.0</td>\n","      <td>77.0</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>306 miles</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>1191805 rows × 31 columns</p>\n","</div>"],"text/plain":["         TRANSACTIONID  FLIGHTDATE AIRLINECODE  \\\n","0             54548800    20020101          WN   \n","1             55872300    20020101          CO   \n","2             54388800    20020101          WN   \n","3             54486500    20020101          WN   \n","4             55878700    20020103          CO   \n","...                ...         ...         ...   \n","1191800      126750200    20130106          EV   \n","1191801      127294500    20130106          DL   \n","1191802      127294900    20130106          DL   \n","1191803      126594900    20130106          EV   \n","1191804      126620300    20130106          EV   \n","\n","                            AIRLINENAME TAILNUM  FLIGHTNUM ORIGINAIRPORTCODE  \\\n","0            Southwest Airlines Co.: WN  N103@@       1425               ABQ   \n","1        Continental Air Lines Inc.: CO  N83872        150               ABQ   \n","2            Southwest Airlines Co.: WN  N334@@        249               ABQ   \n","3            Southwest Airlines Co.: WN  N699@@        902               ABQ   \n","4        Continental Air Lines Inc.: CO  N58606        234               ABQ   \n","...                                 ...     ...        ...               ...   \n","1191800    ExpressJet Airlines Inc.: EV  N683BR       5272               ATL   \n","1191801        Delta Air Lines Inc.: DL  N949DL       1711               ATL   \n","1191802        Delta Air Lines Inc.: DL  N907DE       1810               ATL   \n","1191803    ExpressJet Airlines Inc.: EV  N855AS       5208               ATL   \n","1191804    ExpressJet Airlines Inc.: EV  N138EV       5549               ATL   \n","\n","                                           ORIGAIRPORTNAME ORIGINCITYNAME  \\\n","0         AlbuquerqueNM: Albuquerque International Sunport    Albuquerque   \n","1         AlbuquerqueNM: Albuquerque International Sunport    Albuquerque   \n","2         AlbuquerqueNM: Albuquerque International Sunport    Albuquerque   \n","3         AlbuquerqueNM: Albuquerque International Sunport    Albuquerque   \n","4         AlbuquerqueNM: Albuquerque International Sunport    Albuquerque   \n","...                                                    ...            ...   \n","1191800  AtlantaGA: Hartsfield-Jackson Atlanta Internat...        Atlanta   \n","1191801  AtlantaGA: Hartsfield-Jackson Atlanta Internat...        Atlanta   \n","1191802  AtlantaGA: Hartsfield-Jackson Atlanta Internat...        Atlanta   \n","1191803  AtlantaGA: Hartsfield-Jackson Atlanta Internat...        Atlanta   \n","1191804  AtlantaGA: Hartsfield-Jackson Atlanta Internat...        Atlanta   \n","\n","        ORIGINSTATE ORIGINSTATENAME DESTAIRPORTCODE  \\\n","0                NM      New Mexico             DAL   \n","1                NM      New Mexico             IAH   \n","2                NM      New Mexico             MCI   \n","3                NM      New Mexico             LAS   \n","4                NM      New Mexico             IAH   \n","...             ...             ...             ...   \n","1191800          GA         Georgia             DAL   \n","1191801          GA         Georgia             DFW   \n","1191802          GA         Georgia             DFW   \n","1191803          GA         Georgia             FWA   \n","1191804          GA         Georgia             GSO   \n","\n","                                           DESTAIRPORTNAME  \\\n","0                              DallasTX: Dallas Love Field   \n","1          HoustonTX: George Bush Intercontinental/Houston   \n","2                 Kansas CityMO: Kansas City International   \n","3                      Las VegasNV: McCarran International   \n","4          HoustonTX: George Bush Intercontinental/Houston   \n","...                                                    ...   \n","1191800                        DallasTX: Dallas Love Field   \n","1191801  Dallas/Fort WorthTX: Dallas/Fort Worth Interna...   \n","1191802  Dallas/Fort WorthTX: Dallas/Fort Worth Interna...   \n","1191803             Fort WayneIN: Fort Wayne International   \n","1191804  Greensboro/High PointNC: Piedmont Triad Intern...   \n","\n","                  DESTCITYNAME DESTSTATE   DESTSTATENAME  CRSDEPTIME  DEPTIME  \\\n","0                       Dallas        TX           Texas        1425   1425.0   \n","1                      Houston        TX           Texas        1130   1136.0   \n","2                  Kansas City        MO        Missouri        1215   1338.0   \n","3                    Las Vegas        NV          Nevada        1925   1925.0   \n","4                      Houston        TX           Texas        1455   1453.0   \n","...                        ...       ...             ...         ...      ...   \n","1191800                 Dallas        TX           Texas        1357   1348.0   \n","1191801      Dallas/Fort Worth        TX           Texas        2150   2147.0   \n","1191802      Dallas/Fort Worth        TX           Texas        1617   1617.0   \n","1191803             Fort Wayne        IN         Indiana        1516   1514.0   \n","1191804  Greensboro/High Point        NC  North Carolina        1452   1458.0   \n","\n","         DEPDELAY  TAXIOUT  WHEELSOFF  WHEELSON  TAXIIN  CRSARRTIME  ARRTIME  \\\n","0             0.0      8.0     1433.0    1648.0     4.0        1655   1652.0   \n","1             6.0     12.0     1148.0    1419.0    16.0        1426   1435.0   \n","2            83.0      7.0     1345.0    1618.0     2.0        1500   1620.0   \n","3             0.0      5.0     1930.0    1947.0     1.0        1950   1948.0   \n","4            -2.0     11.0     1504.0    1742.0     5.0        1750   1747.0   \n","...           ...      ...        ...       ...     ...         ...      ...   \n","1191800      -9.0     22.0     1410.0    1500.0     3.0        1523   1503.0   \n","1191801      -3.0     23.0     2210.0    2307.0    10.0        2321   2317.0   \n","1191802       0.0     18.0     1635.0    1728.0     9.0        1750   1737.0   \n","1191803      -2.0     21.0     1535.0    1651.0     4.0        1658   1655.0   \n","1191804       6.0     27.0     1525.0    1611.0     4.0        1609   1615.0   \n","\n","         ARRDELAY  CRSELAPSEDTIME  ACTUALELAPSEDTIME CANCELLED DIVERTED  \\\n","0            -3.0            90.0               87.0         F    False   \n","1             9.0           116.0              119.0     False        F   \n","2            80.0           105.0              102.0         F    False   \n","3            -2.0            85.0               83.0         0        0   \n","4            -3.0           115.0              114.0         F    False   \n","...           ...             ...                ...       ...      ...   \n","1191800     -20.0           146.0              135.0         0        0   \n","1191801      -4.0           151.0              150.0     False        F   \n","1191802     -13.0           153.0              140.0         F    False   \n","1191803      -3.0           102.0              101.0     False        F   \n","1191804       6.0            77.0               77.0     False    False   \n","\n","          DISTANCE  \n","0        580 miles  \n","1        744 miles  \n","2        718 miles  \n","3        487 miles  \n","4        744 miles  \n","...            ...  \n","1191800  721 miles  \n","1191801  731 miles  \n","1191802  731 miles  \n","1191803  508 miles  \n","1191804  306 miles  \n","\n","[1191805 rows x 31 columns]"]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["flights_df"]},{"cell_type":"markdown","metadata":{"id":"uzVzEvaHLYqx"},"source":["Tak więc przechodzenie przez każdą kolumnę identyfikuje problemy, które może mieć zestaw danych. Najpierw zajmijmy się kwestią **odległości**. Wygląda na to, że ma to być zakodowane _całkowite_ (zauważ, że na początku tego wykładu powiedziałem, że odległości mogą być zmiennoprzecinkowe. Dlaczego zmiana zdania?) i mają dopisane 'mile' na końcu numer. Możemy zrobić o wiele więcej rzeczy z danymi liczbowymi niż danymi tekstowymi, które reprezentują liczby, więc najpierw przekonwertujmy to na int.\n","Aalizująć tabelę kolumna po kolumnie dostrzegamy różne problemy, z jakimi musimy się zmierzyć w tym zbiorze danych. Można zacząć od problemu odległości. Wygląda na to, że odległość miała być zakodowana jako integery, ale pojawiają oznaczenia miar. Dane numeryczne pozwalają na o wiele więcej operacji niż dane tekstowe, dlatego należy wyczyścić te wartości tekstowe.\n","\n","<table>\n","    <tr>\n","        <td> </td>\n","        <td><b>OrderID</b></td>\n","        <td><b>Cost</b></td>\n","        <td><b>Quantity</b></td>\n","        <td><b>Address</b></td>\n","    </tr>\n","    <tr>\n","        <td>0</td>\n","        <td>1234</td>\n","        <td>£1000.00</td>\n","        <td>10</td>\n","        <td>123 Fake Street</td>\n","    </tr>\n","    <tr>\n","        <td>1</td>\n","        <td>7890</td>\n","        <td>£35.50</td>\n","        <td>3</td>\n","        <td>789 Real Road</td>\n","    </tr>\n","    \n","</table>\n","W powyższej tabeli widzimy, że koszt powinien być liczbą zmiennoprzecinkową - jednak ma dołączony symbol £. Aby użyć tej kolumny jako float, musimy usunąć £. Jednak zanim to zrobimy, spójrzmy na typy danych kolumn. Odbywa się to poprzez wywołanie atrybutu `.dtypes` w naszej ramce danych. W powyższym przykładzie zwrócilibyśmy:\n","\n","\n","<table>\n","    <tr>\n","        <td>OrderID</td>\n","        <td>int64</td>\n","    </tr>\n","    <tr>\n","        <td>Cost</td>\n","        <td>object</td>\n","    </tr>\n","    <tr>\n","        <td>Quantity</td>\n","        <td>int64</td>\n","    </tr>\n","    <tr>\n","        <td>Address</td>\n","        <td>object</td>\n","    </tr>\n","</table>\n","\n","Możemy również użyć metody `.info()`, która zwraca nam również informacje o wartościach null w każdej kolumnie (wkrótce omówimy, jak radzić sobie z wartościami null/brakującymi wartościami)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mvIMhtpALYq0"},"outputs":[],"source":["## Znajdź typy obiektów dla każdej kolumny za pomocą .dtypes\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"whRww4YGLYq2"},"outputs":[],"source":["## Znajdź typy obiektów i liczbę wartości null za pomocą .info()\n"]},{"cell_type":"markdown","metadata":{"id":"-vZ1UrNULYq4"},"source":["If we were to sum our above <b>cost</b> column (`sales['cost'].sum()`), something akin to the following would be returned:\n","```£1000.00£35.50£46.10£76.35```...\n","\n","Obviously this isn't what we want.. we'd rather have all our costs summed.\n","\n","Try the same with the 'DISTANCE' column with our flights data\n","\n","Gdybyśmy mieli zsumować powyższą kolumnę <b>cost</b> (`sales['cost'].sum()`), zwrócone zostałoby coś podobnego do następującego ciągu:\n","```£1000,00£35.50£46.10£76.35```...\n","\n","Oczywiście nie o to nam chodzi... wolimy zsumować wszystkie nasze koszty.\n","\n","Powtórz ten krok z kolumną „DISTANCE” z danymi dotyczącymi lotów"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"h1AF1FnNLYq9"},"outputs":[],"source":["## Zsumuj pierwsze 10 wystąpień kolumny „DISTANCE” w danych lotów.\n","# Bądź świadomy tego, gdzie używasz slicingu :). Jaka jest techniczna różnica między slicingiem przed .sum() i po?\n","flights_df['DISTANCE'] = flights_df[\"DISTANCE\"].str.strip(\" miles\")\n","flights_df[\"DISTANCE\"] = flights_df[\"DISTANCE\"]"]},{"cell_type":"markdown","metadata":{"id":"XJgUwSoTLYq_"},"source":["Aby rozwiązać problem z naszymi danymi sprzedaży, musimy zrobić dwie rzeczy:\n","1. Usuąć „£”\n","2. Zamienić kolumnę na zmiennoprzecinkowy typ danych\n","\n","Odbywałoby się to w następujący sposób:\n","```python\n","sales['cost'] = sales['cost'].str.strip('£')\n","sales['cost'] = sales['cost'].astype('float64')\n","```\n","\n","Uzbrojeni w tę wiedzę, zamieńmy kolumnę odległości na int!"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1sTpHRvELYrA"},"outputs":[],"source":["## Usuń „mile” z ramki danych\n","flights_df[\"DISTANCE\"] = \n","## Zamień kolumnę na typ int64\n","\n","## Sprawdź, czy kolumna została pomyślnie przekonwertowana na int"]},{"cell_type":"markdown","metadata":{"id":"9IpyIhvFLYrB"},"source":["Świetnie! W ten sposób możemy przekonwertować nieuporządkowane dane tekstowe na liczby. Przyjrzyjmy się teraz konwersji danych na wartości kategoryczne.\n","\n","W naszym zbiorze danych mamy wiele kolumn, które mogą być kategoryczne. Czy potrafisz określić, które to są?\n","<br>\n","<details>\n","    <summary><b>></b> Categorical variables (click to reveal)</summary>\n","    <ul>\n","        <li>AIRLINECODE</li>\n","        <li>AIRLINENAME</li>\n","        <li>ORIGINAIRPORTCODE</li>\n","        <li>ORIGAIRPORTNAME</li>\n","        <li>ORIGINCITYNAME</li>\n","        <li>ORIGINSTATE</li>\n","        <li>ORIGINSTATENAME</li>\n","        <li>DESTAIRPORTCODE</li>\n","        <li>DESTAIRPORTNAME</li>\n","        <li>DESTCITYNAME</li>\n","        <li>DESTSTATE</li>\n","        <li>DESTSTATENAME</li>\n","    </ul>\n","</details>\n","\n","Używając metody `.describe()` możemy dostać więcej informacji o konkretnej kolumnie. Użyjmy jako przykładu `AIRLINECODE`"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3g-_O2p_LYrC"},"outputs":[],"source":["flights_df['DISTANCE'].describe()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dWnfRuo3LYrD"},"outputs":[],"source":["flights_df['AIRLINECODE']"]},{"cell_type":"markdown","metadata":{"id":"O3tMZgVkLYrE"},"source":["Gdy uruchomimy `.describe()` nad tą zmienną, otrzymujemy kilka (średnio) użytecznych statystyk. Widzimy jednak, że typ danych tej kolumny został zinterpretowany jako `object`. Z tabeli typów danych, którą wprowadziliśmy wcześniej, widzimy, że istnieje obsługa kategorii. Przekształćmy to w kategorię i zobaczmy różnicę w stosunku do metody opisu."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9c-qVBAxLYrF","scrolled":true},"outputs":[],"source":["flights_df['AIRLINECODE'] = flights_df['AIRLINECODE'].astype('category')\n","flights_df['AIRLINECODE']"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7RbmqOUALYrG"},"outputs":[],"source":["flights_df['AIRLINECODE'].describe()"]},{"cell_type":"markdown","metadata":{"id":"VHPG7fHoLYrG"},"source":["Tak naprawdę brak widocznej różnicy po użyciu metody `.describe()` (co dziwne, wciąż zwraca dtype object)! Użyjemy metody `.info()`, aby sprawdzić nasze zużycie pamięci"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"USF0oZ8yLYrH","tags":[]},"outputs":[],"source":["flights_df['AIRLINECODE'] = flights_df['AIRLINECODE'].astype('object')\n","flights_df.info()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"B2Z09NL_LYrI","tags":[]},"outputs":[],"source":["flights_df['AIRLINECODE'] = flights_df['AIRLINECODE'].astype('category')\n","flights_df.info()"]},{"cell_type":"markdown","metadata":{"id":"hHR0mRfDLYrL"},"source":["Widzimy, że nasze zużycie pamięci spadło o około 8 MB po przekształceniu tej jednej kolumny w kategorię! Ok, tak, wprawdzie nie jest to wielka sprawa przy pracy z danymi o tym rozmiarze, ale pamiętaj, że oszczędność pamięci pochodzi tylko z jednej z wielu kategorycznych kolumn, które mamy.\n","\n","Więc dlaczego tak jest? Cóż, pod maską Pandas reprezentują kategorie jako typy całkowite. W rzeczywistości coś, na co możesz natknąć się podczas pracy z innymi zestawami danych, to jawne wyświetlanie kolumny kategorii zakodowanej jako liczby całkowite. Zmodyfikujmy naszą ramkę danych, aby zobaczyć, co się stanie dalej."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8GVmfMNULYrN"},"outputs":[],"source":["flights_df['AIRLINECODE_ASINT'] = flights_df['AIRLINECODE'].cat.codes.astype('int8')\n","flights_df['AIRLINECODE_ASINT']"]},{"cell_type":"markdown","metadata":{"id":"MtBq3U1cLYrP"},"source":["Kiedy uruchamiamy `.describe()` możemy zobaczyć zwrócone statystyki, które nie mają sensu dla naszej kolumny:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"u59__uX1LYrP"},"outputs":[],"source":["flights_df['AIRLINECODE_ASINT'].describe()"]},{"cell_type":"markdown","metadata":{"id":"95Cenx8OLYrQ"},"source":["Nie ma sensu, aby kolumna kategoryczna miała średnią lub jakiekolwiek inne właściwości statystyczne."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9QelJMS3LYrQ"},"outputs":[],"source":["flights_df = flights_df.drop('AIRLINECODE_ASINT', 1)"]},{"cell_type":"markdown","metadata":{"id":"2HMVBclnLYrR"},"source":["Jakie typy danych (numeryczne, datetime, tekst lub kategoryczne) przypisałbyś następującym danym?:\n","\n","- Opis przedmiotu\n","- Roczny dochód\n","- Rozmiar odzieży\n","- Czas przylotu samolotu\n","- Urodziny\n","- Smaki koktajli mlecznych w McDonalds\n","- Pierwsza połowa kodu pocztowego\n","- Pełny kod pocztowy\n","- Czas potrzebny biegaczom na ukończenie 5K"]},{"cell_type":"markdown","metadata":{"id":"DHVs9NzqLYrR"},"source":["## Zduplikowane wartości\n","\n","Innym częstym problemem, z którym możemy się spotkać, są **zduplikowane wartości**. Jak sama nazwa wskazuje, dzieje się tak, gdy te same wartości powtarzają się w wielu wierszach lub kolumnach:\n","<table>\n","    <tr>\n","        <td><b>first_name</b></td>\n","        <td><b>last_name</b></td>\n","        <td><b>address</b></td>\n","        <td><b>age</b></td>\n","        <td><b>income</b></td>\n","    </tr>\n","    <tr>\n","        <td>John</td>\n","        <td>Doe</td>\n","        <td>123 Real Street</td>\n","        <td>25</td>\n","        <td>£28000</td>\n","    </tr>\n","    <tr>\n","        <td>Jane</td>\n","        <td>Smith</td>\n","        <td>789 Fake Road</td>\n","        <td>29</td>\n","        <td>£32000</td>\n","    </tr>\n","    <tr>\n","        <td>Jane</td>\n","        <td>Smith</td>\n","        <td>789 Fake Road</td>\n","        <td>29</td>\n","        <td>£32000</td>\n","    </tr>\n","    <tr>\n","        <td>Mark</td>\n","        <td>Smith</td>\n","        <td>789 Fake Road</td>\n","        <td>31</td>\n","        <td>£32000</td>\n","    </tr>\n","</table>\n","\n","W powyższym przykładzie widzimy, że Jane Smith ma dwa wpisy bezpośrednio zduplikowane. Jednak w niektórych przypadkach możemy zobaczyć bardzo podobne wpisy:\n","\n","<table>\n","    <tr>\n","        <td><b>first_name</b></td>\n","        <td><b>last_name</b></td>\n","        <td><b>address</b></td>\n","        <td><b>age</b></td>\n","        <td><b>income</b></td>\n","    </tr>\n","    <tr>\n","        <td>John</td>\n","        <td>Doe</td>\n","        <td>123 Real Street</td>\n","        <td>25</td>\n","        <td>£28000</td>\n","    </tr>\n","    <tr>\n","        <td>Jane</td>\n","        <td>Smith</td>\n","        <td>789 Fake Road</td>\n","        <td><b>28</b></td>\n","        <td>£32000</td>\n","    </tr>\n","    <tr>\n","        <td>Jane</td>\n","        <td>Smith</td>\n","        <td>789 Fake Road</td>\n","        <td>29</td>\n","        <td>£32000</td>\n","    </tr>\n","    <tr>\n","        <td>Mark</td>\n","        <td>Smith</td>\n","        <td>789 Fake Road</td>\n","        <td>31</td>\n","        <td>£32000</td>\n","    </tr>\n","</table>\n","\n","(Różnica wieku między obiema Jane Smith). Ten rodzaj duplikatu błędu jest najprawdopodobniej spowodowany problemem z wprowadzaniem danych lub ponownym przesłaniem dowolnego formularza złożonego przez Jane – który został wprowadzony do bazy danych bez usuwania jej starego wpisu.\n","\n","Najczęściej jednak duplikaty danych wynikają z błędów/wzorców projektowych w potokach danych lub najczęściej z łączenia baz danych i konsolidacji danych z różnych zestawów danych/baz danych, które mogą zachować zduplikowane wartości.\n","\n","Pandas udostępnia nam metodę [`.duplicated()`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.duplicated.html). Użyjmy tego w naszej ramce danych, aby zobaczyć, co zwraca"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fslvxoC7LYrS"},"outputs":[],"source":["flights_df.duplicated()"]},{"cell_type":"markdown","metadata":{"id":"qm1kK2YaLYrU"},"source":["Zauważ, że możemy użyć `.sum()` do wartości logicznych. Zasadniczo False są interpretowane jako 0, a True jako 1. Tak więc sumując ramkę danych, możemy uzyskać całkowitą liczbę zduplikowanych wartości!"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2XJBdjnnLYrU"},"outputs":[],"source":["flights_df.duplicated().sum()"]},{"cell_type":"markdown","metadata":{"id":"DfU3KHMXLYrV"},"source":["Brak duplikatów to dobry wynik, ale nie dajmy się zwieść. Przypomnijmy sobie duplikat Jane Smith powyżej. Zduplikowana metoda nie zwróciłaby wartości true, ponieważ cały wiersz nie był dokładnym duplikatem. Dlatego możemy w metodzie `.duplicated()` skorzystać z dwóch argumentów: `subset` i `keep`. Dla argumentu subset podaj listę nazw kolumn, w których chcemy sprawdzić duplikaty, a w argumencie keep podaj  1 z 3 wartości: „pierwsza”, „ostatnia” lub „Fałsz”. Z dokumentacji wiemy, że:\n","- `first` : Oznacz duplikaty jako True z wyjątkiem pierwszego wystąpienia.\n","- `last` : Zaznacz duplikaty jako True z wyjątkiem ostatniego wystąpienia.\n","- `False` : Oznacz wszystkie duplikaty jako True.\n","\n","W wielu przypadkach wybranie podzbioru jest bardziej intuicyjne niż naukowe."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DiIyZOlwLYrV"},"outputs":[],"source":["## Znajdź duplikaty w ramce danych lotów w następujących kolumnach, ustaw keep = False:\n"," # \"ORIGAIRPORTNAME\", \"DESTAIRPORTNAME\", \"AIRLINECODE\", \"FLIGHTDATE\", \"CRSDEPTIME\", \"DEPTIME\", \"ARRTIME\"\n"," # Przypisz to zmiennej 'duplicates'\n"," # Czy wybrałam dobre klolumny? Postąpiłbyś inaczej?\n","\n","    \n","# Używając df[duplikaty], zwracane są punkty danych, w których istnieją duplikaty.\n","## Zwróć duplikaty dla ramki danych lotów\n"]},{"cell_type":"markdown","metadata":{"id":"2hzEsurbLYrW"},"source":["Jako drugorzędną obserwację widzimy, że „TALINUM” również przyjmuje wartość „UNKNOWN” dla brakujących wartości. Zanotujemy to, abyśmy mogli zająć się tym później.\n","\n","Aby posortować naszą ramkę danych, możemy użyć metody [`.sort_values()`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.sort_values.html). Przeczytaj dokumentację i użyj tej metody, aby posortować ramkę danych według nazwy kolumny, która Twoim zdaniem jest odpowiednia (taka, która pozwala łatwo zweryfikować, czy zwrócone wpisy są faktycznymi duplikatami)."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jnqXT_zULYrX"},"outputs":[],"source":["## Posortuj zduplikowane wartości według odpowiedniego indeksu\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"t0y9FfuLLYrY","scrolled":false},"outputs":[],"source":["flights_df[\"TAILNUM\"].isna().sum()"]},{"cell_type":"markdown","metadata":{"id":"ioHBRmk8LYrZ"},"source":["### Radzenie sobie z duplikatami\n","\n","Mamy dwie opcje:\n","1. Uśrednienie wartości, tam gdzie to możliwe\n","2. Usunięcie jednego z duplikatów (lub wielu, tak by pozostał pojedynczy wiersz)\n","\n","\n","##### Uśrednianie\n","\n","Uśrednianie po zduplikowanych wartościach można tak naprawdę wykonać tylko na typach danych, które mają sens. W powyższej tabeli pierwsze dwa wpisy mają prawidłowe czasy, które możemy uśrednić. Ogólnie rzecz biorąc, sposób, w jaki uśredniamy, to grupowanie według odpowiednich kolumn (poprzez `.groupby()`) i łączenie tego z funkcją `.agg()`. W tym przypadku chcemy pogrupować wg kolumn w podzbiorze poza kolumnami, które nas interesują (np. wg. czasu). Naszym argumentem do `.agg()` jest słownik z parami klucz-wartość nazw kolumn i funkcją agregacji, którą chcemy nad nimi zastosować (np. suma, różnica, średnia itp.)."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tRu5jXOwLYrc","scrolled":false,"tags":[]},"outputs":[],"source":["summaries = {\"CRSARRTIME\": \"mean\", \"ARRTIME\": \"mean\", \"ARRDELAY\": \"mean\", \"CRSELAPSEDTIME\": \"mean\", \"ACTUALELAPSEDTIME\": \"mean\"}\n","\n","grouped_duplicates = flights_df[duplicates].groupby([\"FLIGHTDATE\", \"AIRLINECODE\", \"ORIGAIRPORTNAME\", \"DESTAIRPORTNAME\"])\n","grouped_duplicates_min_transactionid = grouped_duplicates[\"TRANSACTIONID\"].min().reset_index()\n","\n","f_df_duplicates = pd.merge(\n","    grouped_duplicates_min_transactionid,\n","    grouped_duplicates.agg(summaries).reset_index(),\n","    how=\"inner\"\n",").sort_values(\"TRANSACTIONID\")\n","\n","f_df_duplicates\n"]},{"cell_type":"markdown","metadata":{"id":"nEWgXqT-ri_O"},"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3AEEhirqLYrd"},"outputs":[],"source":["# Dlaczego w polu TRANSACTIONID jest teraz tak wiele nowych NaN?\n","## Jak się ich pozbyć?\n","\n","\n","## Ponownie zakoduj TRANSACTIONID do int64\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Njgc4uqVLYrh","tags":[]},"outputs":[],"source":["# Metoda .update() pozwala nam aktualizować rekordy w jednej ramce danych na podstawie wartości w innej\n","# Potrzebny jest pewien sposób \"powiązania\" rekordów do nadpisania/aktualizacji, jeśli nie chcemy używać domyślnego indeksu ramki danych\n","## Tak więc, używając metody .set_index(), ustaw ramkom flight_df i f_df_duplicates nowy indeks na unikalny klucz indentifera, który obaj współdzielą\n","\n","\n","# Teraz możemy zaktualizować ramkę flight_df o nową ramkę danych\n","\n","## I na koniec możemy opcjonalnie zresetować indeks, aby uzyskać domyślne indeksowanie ramki danych\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_NF3Rpuos1tn"},"outputs":[],"source":["flights_df.head(2)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ti9zul4uLYri"},"outputs":[],"source":["flights_df[flights_df[\"TRANSACTIONID\"]==1974100]"]},{"cell_type":"markdown","metadata":{"id":"mhE7iHqPLYrj"},"source":["##### Usuwanie duplikatów\n","\n","Jeśli chodzi o usuwanie duplikatów, Pandas udostępnia nam metodę `.drop_duplicates()`, która przyjmuje trzy argumenty:\n","1. `subset`\n","2. `keep`\n","3. `inplace` - wartość boolean, czy chcemy nadpisać ramkę czy nie"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uWTWGoZmLYrj"},"outputs":[],"source":["subset = [\"ORIGAIRPORTNAME\", \"DESTAIRPORTNAME\", \"AIRLINECODE\", \"FLIGHTDATE\", \"CRSDEPTIME\", \"DEPTIME\", \"ARRTIME\"]\n","## Używając inplace = True, usuń duplikaty. Zastanów się, jaką wartość powinniśmy ustawić argumentowi keep\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"b2E4w_2nLYrk","scrolled":false},"outputs":[],"source":["flights_df[duplicates].tail()"]},{"cell_type":"markdown","metadata":{"id":"7b0dzVwRLYrl"},"source":["## Dane kategoryczne\n","\n","Wspomnieliśmy już o danych kategorycznych wcześniej, ale tutaj bardziej szczegółowo zdefiniujemy to pojęcie. Zmienne danych kategorycznych przyjmują swoją wartość z predefiniowanego zestawu kategorii. Widzieliśmy powyższy przykład z kodami AIRLINE.\n","\n","Czy poniższe zmienne są kategoryczne?\n","- TAILNUM\n","- FLIGHTNUM\n","- ORIGINAIRPORTCODE\n","- ORIGAIRPORTNAME\n","- CANCELLED\n","\n","A kolumny w poniższej tabeli?\n","\n","<table>\n","    <tr>\n","        <td><b>First Name</b></td>\n","        <td><b>Last Name</b></td>\n","        <td><b>Age</b></td>\n","        <td><b>Address</b></td>\n","        <td><b>District Postcode</b></td>\n","        <td><b>Full Postcode</b></td>\n","        <td><b>Married</b><td>\n","    </tr>\n","    <tr>\n","        <td>John</td>\n","        <td>Doe</td>\n","        <td>31</td>\n","        <td>123 Fake Street, Realtown</td>\n","        <td>RT1</td>\n","        <td>RT1 3NV</td>\n","        <td>True</td>\n","    </tr>\n","    <tr>\n","        <td>Diane</td>\n","        <td>Smith</td>\n","        <td>31</td>\n","        <td>42 World Road, Realtown</td>\n","        <td>RT2</td>\n","        <td>RT2 7XU</td>\n","        <td>False</td>\n","    </tr>\n","    <tr>\n","        <td>Kate</td>\n","        <td>Doe</td>\n","        <td>29</td>\n","        <td>123 Fake Street, Realtown</td>\n","        <td>RT1</td>\n","        <td>RT1 3NV</td>\n","        <td>False</td>\n","    </tr>\n","    <tr>\n","        <td>Charlie</td>\n","        <td>Doe</td>\n","        <td>33</td>\n","        <td>789 Real Road, Fakecity</td>\n","        <td>FC2</td>\n","        <td>FC2 9ER</td>\n","        <td>True</td>        \n","    </tr>    \n","</table>\n","Dane kategoryczne mogą przyjmować tylko jedną ze skończonego zestawu wartości i nie jest możliwe, aby wykroczyły poza te uprzednio zdefiniowane kategorie. Jednak podczas procesu zbierania danych może wystąpić szum w naszych danych (np. jeśli nasze dane kategoryczne zostały zebrane za pomocą okienka tekstowego do wprowadzania dowolnej treści).\n","\n","\n","Istnieje kilka sposobów radzenia sobie z niespójnymi kategoriami:\n","1. Usuwanie danych\n","2. Zmiana mapowania kategorii\n","3. Wnioskowanie kategorii\n","\n","### Usuwanie danych\n","\n","\n","Przyjrzyjmy się kolumnie `ORIGINSTATENAME`. Usunięcie danych jest wymagane, gdy mamy wartość, która w naszym wpisie nie znajduje się (koncepcyjnie) we wstępnie zdefiniowanym zestawie kategorii. Zaczniemy od zwrócenia wszystkich unikalnych wartości w zmiennej."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sW8mXOLhLYrl"},"outputs":[],"source":["## skonstruuj zbiór unikalnych wartości w ORIGINSTATENAME\n","\n","states"]},{"cell_type":"markdown","metadata":{"id":"vuKmhBJDLYrm"},"source":["Załóżmy teraz, że otrzymaliśmy kilka nowych wpisów, których nazwy stanów nie występują w tym predefiniowanym zestawie kategorii (na przykład „Fakestate”)."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PJKExsdqLYrm"},"outputs":[],"source":["## używając metody .at() lub .iat() na flight_df, zmodyfikuj jeden z wierszy\n","## w naszej tabeli, aby mieć ORIGINSTATENAME jako Fakestate\n","# https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.at.html\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"emj6CK9iLYrm"},"outputs":[],"source":["# Wyświetl unikalne wpisy w ORIGINSTATENAME w naszej zmodyfikowanej ramce danych\n","\n","# LUB set(flights_df[\"ORIGINSTATENAME\"])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8XQau4l5LYrn"},"outputs":[],"source":["## Korzystając z operacji set, znajdź różnicę między stanami początkowymi w naszej ramce danych a naszą predefiniowaną listą\n","\n","inconsistent_categories"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5LRnimYGLYrn"},"outputs":[],"source":["# Metoda .isin zwraca wszystkie wiersze z ramki danych, w których został spełniony p[rzekazany warunek]\n","\n","flights_df[inconsistent_rows]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"n6e7KsZWLYro"},"outputs":[],"source":["# Sprytna sztuczka, której możemy użyć do usunięcia wierszy\n","# Jak myślisz, co oznacza ~?\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bS51Zn6hvNxD"},"outputs":[],"source":["set(flights_df['ORIGINSTATENAME'])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eEH_Q-kTvNv-"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"UhfXnORSLYro"},"source":["### Zmiana mapowania kategorii\n","\n","To, co widzieliśmy powyżej, to dane, których nie było w predefiniowanym zestawie kategorii. Jednak możemy również natknąć się na inny rodzaj problemów z danymi kategorycznymi, które lepiej rozwiązywać poprzez ponowne mapowanie kategorii niż usuwanie danych. Odpowiednie miejsca do wykonania tego ponownego mapowania to:\n","1. **Niespójność wartości**: „żonaty”, „niezamężna”, „stanu wolnego”, „ożeniony” <br>\n"," 1. Uważaj też na końcowe białe znaki!\n","2. **Konwertowanie danych na kategorie lub zbyt wiele kategorii**: Załóżmy, że w naszej ramce danych mamy kolumnę dochodu gospodarstwa domowego.\n"," 1. Możemy zmienić ten typ danych na kategoryczny, grupując dochody (np. `0 - 20k`, `20k - 40k`, `40k - 60k`, `60k +` itd.).\n"," 2. Możemy również zredukować to dalej do `low_class`, `middle_class`, `upper_class`\n"," \n","Zajmijmy się nimi w kolejności. W naszej ramce danych lotów kolumny „CANCELLED” i „DIVERTED” przyjmują niespójne wartości. Być może najbezpieczniejszą opcją jest uruchomienie `.value_counts()` na jednej z tych kolumn (`.value_counts()` działa na danych typu `Series`)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CigO83vkLYro"},"outputs":[],"source":["flights_df[\"CANCELLED\"].value_counts()"]},{"cell_type":"markdown","metadata":{"id":"MtZjIeBlLYrp"},"source":["Świetnie! Widzimy więc, że nasze Fałszywe wartości mogą przyjąć jedną z trzech wartości, a wartości Prawdy też są podobne. Możemy arbitralnie wykorzystać te, których chcemy użyć, posuwając się do przodu. Dla jednoznaczności wybierzmy odpowiednio False i True."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Eb4UloJQLYrs"},"outputs":[],"source":["## Skorzystaj z metody replace: https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.replace.html\n","## Aby zamienić 0, F, 1 and T na odpowiadające wartości w kolumnie CANCELLED\n",")\n","flights_df[\"CANCELLED\"].value_counts()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"e_O-7fSVLYrt"},"outputs":[],"source":["flights_df[\"DIVERTED\"].value_counts()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FF16YDZhLYrv"},"outputs":[],"source":["# Możemy alternatywnie użyć słownika, aby \"zredukować\" nasze kategorie.\n","mapping = \n","\n","flights_df[\"DIVERTED\"].value_counts()"]},{"cell_type":"markdown","metadata":{"id":"GQz1nopdLYrv"},"source":["Jak wspomniano wcześniej, inną sytuacją, w której możemy chcieć ponownie przyporządkować kategorie, jest zmniejszenie liczby wartości w kolumnie. W naszym przypadku załóżmy, że firma lotnicza chciałaby sklasyfikować loty na podstawie długości tras. Tak więc wszystko między 0 a 1000 mil jest `short`, między 1000 a 2500 to `medium`, a 2500+ to `long`.\n","\n","Możemy użyć metody [`.cut`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.cut.html) aby zaklasyfikować dane. Musimy podać 3 argumenty:\n","1. `Series`, którą chcemy sklasyfikować\n","2. Bins - liczbę przedziałów\n","3. Labels - etykiety do przypisania przydziałom"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xXkSml-3LYrw"},"outputs":[],"source":["import numpy as np\n","\n","bins = [0, 1000, 2500, np.inf]\n","labels = [\"short\", \"medium\", \"long\"]\n","flights_df[\"DISTANCE_CATEGORY\"] = pd.cut(flights_df[\"DISTANCE\"], bins=bins, labels=labels)\n","\n","flights_df[[\"DISTANCE\", \"DISTANCE_CATEGORY\"]]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"spKk3mZkLYrw","scrolled":false},"outputs":[],"source":["flights_df[flights_df[\"DISTANCE_CATEGORY\"] == \"long\"]"]},{"cell_type":"markdown","metadata":{"id":"f9NPqHsLLYrx"},"source":["### Radzenie sobie z danymi datoczasowymi\n","\n","Jednym z typowych problemów, z którymi się spotkasz, jest zajmowanie się datami i godzinami. Czemu? Ponieważ istnieje wiele sposobów formatowania daty, na przykład `DD/MM/RRRR`, `MM/DD/RR`, `X. MIESIĄC ROK` itp. W powyżej ramce danych nasze daty są w rzeczywistości sformatowane jako jedna numer. Pandas dostarcza nam przydatnego pomocnika do konstruowania dat i godzin — to znaczy metodę [`.to_datetime()`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.to_datetime.html ).\n","\n","Zanim się tym zajmiemy, warto szybko przedstawić, w jaki sposób daty są zwykle przechowywane na komputerach. Zazwyczaj daty są obliczane na podstawie liczby sekund, które upłynęły od **1 stycznia 1970**. Gdy chcemy, znaleźć różnicę w czasie między 3.02.2013 16:00 a 21.01.2013 09:00, program wykonuje swoje operacje na **czasie Epoka/Unix/POSIX** dla tych wartości, a następnie możemy coś zakodować, aby otrzymać wartość z powrotem w wybranym przez nas formacie (np. 13 dni, 7 godzin). Posługując się liczbami:\n","\n","- **3/2/2013 16:00** = 1,359,907,200\n","- **21/1/2013 09:00** = 1,358,758,800\n","\n","Różnica w datach = 1,359,907,200 - 1,358,758,800 = 1,148,400 sekund\n","\n","`format(1148400) = 13 dni, 7 godzin`\n","\n","Przykłady formatowania dat:\n","<table>\n","    <tr>\n","        <td><b>Date</b></td>\n","        <td><b>Datetime format</b></td>\n","    </tr>\n","    <tr>\n","        <td>15th June 2020</td>\n","        <td>%c</td>\n","    </tr>\n","    <tr>\n","        <td>15/06/2020</td>\n","        <td>%d/%m/%Y</td>\n","    </tr>\n","    <tr>\n","        <td>06-15-2020</td>\n","        <td>%m-%d-%Y</td>\n","    </tr>\n","</table>\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KYdrXAWsLYrx"},"outputs":[],"source":["pd.to_datetime(flights_df[\"FLIGHTDATE\"])"]},{"cell_type":"markdown","metadata":{"id":"AkrrldXzLYry"},"source":["To dlaczego teraz wszystkie daty to 1970-01-01?\n","\n","A to dlatego, że daty są wewnętrznie przechowywane jako sekundy (liczby). Nasza kolumna `FLIGHTDATE` również wyświetla daty lotów w postaci liczb. Tak więc, kiedy uruchamiamy metodę `.to_datetime()`, wszystkie nasze daty są interpretowane jako czas POSIX.\n","\n","Jednym z prostych rozwiązań, aby to naprawić, jest jawne określenie naszego formatu daty i godziny. Biorąc pod uwagę powyższe przykłady, jak myślisz, jaki będzie format daty?\n","One simple solution we can do to fix that is to explicitly specify our datetime?"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"R4IkNWSiLYrz"},"outputs":[],"source":["## Przypisywanie formatu\n","\n","flights_df[\"FLIGHTDATE\"]"]},{"cell_type":"markdown","metadata":{"id":"TVs0VDyQLYr1"},"source":["To rozwiązanie było dość specyficzne dla problemu, który mieliśmy pod ręką. Ale w prawdziwym świecie często można napotkać mieszane formaty dat w jednej ramce danych. Na przykład:\n","\n","<table>\n","    <tr>\n","        <td><b>Name</b></td>\n","        <td><b>Date of Birth</b></td>\n","        <td><b>Age</b></td>\n","    </tr>\n","    <tr>\n","        <td>John</td>\n","        <td>01/07/1995</td>\n","        <td>25</td>\n","    </tr>\n","    <tr>\n","        <td>Jane</td>\n","        <td>20-04-1992</td>\n","        <td>28</td>\n","    </tr>\n","    <tr>\n","        <td>Mark</td>\n","        <td>3rd January 1990</td>\n","        <td>30</td>\n","    </tr>\n","    </table>\n","\n","\n","`.to_datetime()` ponownie przychodzi tutaj na ratunek! W poprzedniej komórce kodu wyraźnie ustawiliśmy format daty (ze względu na nietypowy charakter sposobu przechowywania tej daty w ramce danych) - ale bardziej ogólnie możemy użyć `.to_datetime()`, aby automatycznie wywnioskować format każdej daty z osobna.\n","\n","```python\n","# errors='coerce' means we'll return NA rows for invalid dates\n","df[\"DATE\"] = pd.to_datetime(df[\"DATE\"], infer_datetime_format=True, errors='coerce') \n","```"]},{"cell_type":"markdown","metadata":{"id":"powV2fiNLYr6"},"source":["## Walidacja krzyżowa\n","\n","Co to znaczy sprawdzić integralność naszych danych? Zasadniczo musimy mieć świadomość, że kolumna danych, które widzimy, jest spójna w oparciu o inne kolumny danych. Właśnie to sprawdza się w **walidacji krzyżowej**. Zanim rozszerzę niektóre walidacje krzyżowe w tym zbiorze danych, przedstawię nieco bardziej trywialny przykład, aby pokazać, gdzie niewykonanie takich kontroli może zniekształcić analizę:\n","\n","Poniższa fikcyjna tabela pokazuje wpisy niektórych posiadaczy kredytów studenckich na studia licencjackich (UG) i podyplomowych (PG). Zestaw danych składa się z imienia i nazwiska kredytobiorcy, daty urodzenia (DOB), obecnego wieku (lub wieku zmarłego, jeśli dotyczy, niezależnie od tego, czy zmarli, czy też nie), kwoty ich kredytu UG i PG oraz całkowite kwoty, którą są winni – co powinno być sumą dwóch poprzednich pól. W poniższej tabeli zaznaczono wątpliwe pola kursywą.\n","\n","<table>\n","    <tr>\n","        <td><b>Name</b></td>\n","        <td><b>D.O.B</b></td>\n","        <td><b>Age</b></td>\n","        <td><b>Deceased</b></td>\n","        <td><b>U.G Loan (£)</b></td>\n","        <td><b>P.G Loan (£)</b></td>\n","        <td><b>Total Loan (£)</b></td>\n","    </tr>\n","    <tr>\n","        <td>Idaline</td>\n","        <td>1971-04-27</td>\n","        <td>49</td>\n","        <td>F</td>\n","        <td>24100</td>\n","        <td>11900</td>\n","        <td>36000</td>\n","    </tr>\n","    <tr>\n","        <td>Freddie</td>\n","        <td>1962-12-27</td>\n","        <td>57</td>\n","        <td>F</td>\n","        <td>26600</td>\n","        <td>12600</td>\n","        <td>39200</td>\n","    </tr>\n","    <tr>\n","        <td>Debee</td>\n","        <td>1970-11-19</td>\n","        <td>49</td>\n","        <td>F</td>\n","        <td>32400</td>\n","        <td>97000</td>\n","        <td><i>42100</i></td>\n","    </tr>\n","    <tr>\n","        <td>Joyann</td>\n","        <td>1957-01-24</td>\n","        <td><i>41</i></td>\n","        <td>T</td>\n","        <td>24400</td>\n","        <td>11500</td>\n","        <td>35900</td>\n","    </tr>\n","    <tr>\n","        <td>Ajay</td>\n","        <td>1960-05-12</td>\n","        <td><i>50</i></td>\n","        <td>F</td>\n","        <td>25500</td>\n","        <td>18800</td>\n","        <td>44300</td>\n","    </tr>\n","    <tr>\n","        <td>Emelia</td>\n","        <td>1957-11-23</td>\n","        <td><i>57</i></td>\n","        <td>T</td>\n","        <td>34000</td>\n","        <td>17500</td>\n","        <td><i>0</i></td>\n","    </tr>\n","            \n","</table>\n","            \n","            ajay, emelia, joyann"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kR0z-XkwLYr6"},"outputs":[],"source":["html_table = \"\"\"\n","<table>\n","    <tr>\n","        <td><b>Name</b></td>\n","        <td><b>D.O.B</b></td>\n","        <td><b>Age</b></td>\n","        <td><b>Deceased</b></td>\n","        <td><b>U.G Loan (£)</b></td>\n","        <td><b>P.G Loan (£)</b></td>\n","        <td><b>Total Loan (£)</b></td>\n","    </tr>\n","    <tr>\n","        <td>Idaline</td>\n","        <td>19710427</td>\n","        <td>50</td>\n","        <td>F</td>\n","        <td>24100</td>\n","        <td>11900</td>\n","        <td>36000</td>\n","    </tr>\n","    <tr>\n","        <td>Freddie</td>\n","        <td>19621227</td>\n","        <td>58</td>\n","        <td>F</td>\n","        <td>26600</td>\n","        <td>12600</td>\n","        <td>39200</td>\n","    </tr>\n","    <tr>\n","        <td>Debee</td>\n","        <td>19701119</td>\n","        <td>49</td>\n","        <td>F</td>\n","        <td>32400</td>\n","        <td>97000</td>\n","        <td><i>42100</i></td>\n","    </tr>\n","    <tr>\n","        <td>Joyann</td>\n","        <td>19570124</td>\n","        <td><i>41</i></td>\n","        <td>T</td>\n","        <td>24400</td>\n","        <td>11500</td>\n","        <td>35900</td>\n","    </tr>\n","    <tr>\n","        <td>Ajay</td>\n","        <td>19600512</td>\n","        <td><i>50</i></td>\n","        <td>F</td>\n","        <td>25500</td>\n","        <td>18800</td>\n","        <td>44300</td>\n","    </tr>\n","    <tr>\n","        <td>Emelia</td>\n","        <td>19571123</td>\n","        <td><i>57</i></td>\n","        <td>T</td>\n","        <td>34000</td>\n","        <td>17500</td>\n","        <td><i>0</i></td>\n","    </tr>\n","            \n","</table>\n","\"\"\"\n","\n","html_df = pd.read_html(html_table, header=0)[0]\n","html_df"]},{"cell_type":"markdown","metadata":{"id":"S-i21GnyLYr-"},"source":["Najpierw popracujmy nad zmienną **Age**. Zgodnie z naszą dokumentacją danych, wiek w komórce powinien odzwierciedlać aktualny wiek kredytobiorców. Wyjątkiem jest sytuacja, gdy kredytobiorca nie żyje, w którym to przypadku wiek powinien zawierać wiek kredytobiorcy w momencie jego śmierci. Najpierw ustalmy, które wiersze łamią ten warunek."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qepP679ELYr_"},"outputs":[],"source":["# najpierw zmieńmy nazwy niektórych kolumn\n","\n","html_df.info()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yTLV5F1tLYsA"},"outputs":[],"source":["## Zamie nmy 'dob' na obiekt date\n","\n","html_df"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QxfQXSY7LYsA"},"outputs":[],"source":["# Stwórz nową kolumnę „now_date” wypełnioną aktualną datą i godziną\n","html_df[\"now_date\"] \n","\n","## Oblicz różnicę między 'dob' i 'now_date' i zwróć wartość jako lata\n","now_date_dob_difference = \n","now_date_dob_difference"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OVZohQSNLYsB"},"outputs":[],"source":["# Ta linia zmienia obiekty timedate na rok zmiennoprzecinkowy, który następnie konwertujemy na int\n","now_date_dob_difference = \n","now_date_dob_difference"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pdbHB3J1LYsC"},"outputs":[],"source":["# Na oko możemy zobaczyć, który wiek nie pasuje do ramki danych, którą pokazaliśmy wcześniej.\n","# Jednak ogólnie zakodujmy to za pomocą logiki pandas.\n","## Zwróć wiersze, w których „now_date_dob_difference” różni się od zmiennej wieku ramki danych\n","html_df[html_df[\"age\"] "]},{"cell_type":"markdown","metadata":{"id":"EptEtKrqLYsC"},"source":["Przyjrzyjmy się, dlaczego powyższe komórki zostały zwrócone. Jak wspomniano wcześniej, jeśli pożyczkobiorca nie żyje, jego wiek powinien to odzwierciedlać. Oznacza to, że wiek Joyann i Emelii jest rzeczywiście prawidłowy. Używając logiki, odfiltrujmy te wiersze, aby zwrócić tylko te wiersze, które mają matematycznie niepoprawny wiek."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"929fTM1BLYsD"},"outputs":[],"source":["## Odfiltruj odpowiednich pożyczkodawców za pomocą logiki (wskazówka: &)\n","incorrect_age_rows \n","incorrect_age_rows"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"i0TOPBMXLYsD"},"outputs":[],"source":["## Zaktualizuj ramkę danych invalid_age_rows o poprawiony wiek\n","incorrect_age_rows[\"age\"] \n","incorrect_age_rows"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RpUiCcuxLYsE"},"outputs":[],"source":["## Teraz zaktualizuj odpowiednie wpisy html_df o kolumnę wieku z ramki danych invalid_age_rows\n","html_df.update(incorrect_age_rows[\"age\"])\n","html_df"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bDKWYHMlLYsE"},"outputs":[],"source":["## Konwertuj wiek z powrotem na int\n","html_df[\"age\"] = \n","## Usuń kolumnę now_date\n","\n","html_df"]},{"cell_type":"markdown","metadata":{"id":"6U-9GkR3LYsE"},"source":["Popracujmy teraz nad kwotami pożyczki. Zwróć wszystkie kolumny, w których `ug_loan` + `pg_loan` nie są równe `total_loan`"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kco3vfiQLYsF"},"outputs":[],"source":["## Podzbiór `ug_loan` i `pg_loan` z naszej ramki danych, a następnie sumowanie wzdłuż osi kolumny\n","sum_loans = \n","sum_loans"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OY-s7WcPLYsF"},"outputs":[],"source":["## Zwróć wiersze, które mają nieprawidłowe wartości sum\n","incorrect_loan_rows = \n","incorrect_loan_rows"]},{"cell_type":"markdown","metadata":{"id":"rcX8EJxCLYsG"},"source":["### Jak postępować z polami, które nie przeszły walidacji?\n","\n","Tutaj widzimy dwa wiersze, które nie zawierają poprawnych całkowitych kwot kredytu. Analizując każdy z nich z osobna, widzimy, że dane w pierwszym wierszu najprawdopodobniej zawierały niepoprawną wartość `pg_loan` (97 000 GBP w przypadku pożyczki podyplomowej). W drugim, z jakiegoś powodu wartość `total_loan` nie została obliczona. Naiwną strategią może być nadpisanie całkowitych kwot pożyczki sumą `ug_loan` i `pg_loan`. To naprawia typy błędów, w których zwracany jest drugi wiersz. Jednak może istnieć podstawowy problem z powodu pierwszego rzędu. Jeśli zsumujemy tutaj `ug_loan` i `pg_loan`, utworzymy **obserwację odstającą**. W prawdziwym zbiorze danych mogą wystąpić bardzo realne zagrożenia, takie jak te, które mogą narazić na szwank integralność danych – takie problemy mogą łatwo wymykać się spod kontroli, więc upewnij się, że poświęcisz czas na przemyślenie, w jaki sposób Twoje działania wpłyną na Twój dane.\n","\n","Jak wspomniano wcześniej, niektóre aspekty nauki o danych są sztuką – ale jakąkolwiek decyzję heurystyczną podejmiemy, musimy znaleźć dla niej mocne uzasadnienie. W tym konkretnym przypadku zamierzam usunąć wiersze z niepoprawnym `total_loan`, ponieważ ten błąd prawdopodobnie wystąpił z powodu błędu we wprowadzaniu danych przez człowieka. Wiersze z `total_loan = 0` prawdopodobnie wystąpiły z powodu jakiegoś systematycznego błędu - być może z innej bazy danych, w której nie podano sumy total_loan. Biorąc pod uwagę inne weryfikacje, jednym z rozwiązań, które moglibyśmy wybrać, jest zsumowanie dwóch kolumn."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3LYmqAwZLYsG"},"outputs":[],"source":["## Zidentyfikuj wiersze, w których total_loan NIE jest równe 0, ale jest niepoprawne\n","\n","print(incorrect_loan_but_not_zero_rows)\n","\n","## Usuń te wiersze\n","html_df = \n","\n","html_df"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gGWk1vQ70JQG"},"outputs":[],"source":["html_df[(html_df[\"total_loan\"] == 0)]\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dH61qpbu0kj9"},"outputs":[],"source":["html_df.drop(index=5, inplace=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iFsOwL5fLYsH"},"outputs":[],"source":["# Zakładając, że jesteśmy zadowoleni ze wszystkich innych wpisów w naszych pożyczkobiorcach, możemy bezpośrednio obliczyć i nadpisać total_loan w naszej ramce danych\n","## Zastąp total_loan sumą ug_loan i pg_loan\n","html_df[\"total_loan\"] = \n","html_df"]},{"cell_type":"markdown","metadata":{"id":"OJtBNq4VLYsI"},"source":["## Praca z danymi tekstowymi i typu string\n","\n","Dane tekstowe są oczywiście niezwykle powszechnym rodzajem danych i mogą przybierać różne formy – od tekstu nieustrukturyzowanego po e-maile, nazwiska, numery telefonów itp. Istnieje wiele rodzajów problemów, które możemy napotkać w przypadku danych tekstowych:\n","- Niespójność danych (np. +86 195 448 8582 vs 0086-195-448-8582)\n","- Naruszenia tekstu (np. niedozwolone znaki, błędy w polach wejściowych, literówki w tekście)\n","- Literówki „strukturalne” (np. +86.1954.48858.2)\n","\n","W przykładowej tabeli poniżej widzimy listę osób wraz z ich imionami i numerami telefonów. Jak widać – najprawdopodobniej ze względu na wolne pola tekstowe, nazwiska i numery telefonów zostały wprowadzone w różnych formatach. Naszym zadaniem jest standaryzacja tych pól, aby były spójne w całej ramce danych:\n","\n","<table>\n","    <tr>\n","        <td><b>Name</b></td>\n","        <td><b>Phone Number</b></td>\n","    </tr>\n","    <tr>\n","        <td>Dr Darci Abela</td>\n","        <td>+86-185-338-1819</td>\n","    </tr>\n","    <tr>\n","        <td>Mr Patten St. Queintain</td>\n","        <td>00865872411917</td>\n","    </tr>\n","    <tr>\n","        <td>mr conant burden</td>\n","        <td>0086-289-702-0948</td>\n","    </tr>\n","    <tr>\n","        <td>miss marcia Dutnell</td>\n","        <td>0668</td>\n","    </tr>\n","    <tr>\n","        <td>dr Greggory lurner</td>\n","        <td>+31 778 813 8432</td>\n","    </tr>\n","    <tr>\n","        <td>MS Doe Beavan</td>\n","        <td>+420-731-276-7633</td>\n","    </tr>\n","    <tr>\n","        <td>Tamarah Delgado</td>\n","        <td>+868431029051</td>\n","    </tr>\n","    <tr>\n","        <td>Miss Arlee daborne</td>\n","        <td>+33-307-220-2746</td>\n","    </tr>\n","    <tr>\n","        <td>Ly b. Grima</td>\n","        <td>+238-863-946-4232</td>\n","    </tr>\n","</table>\n","\n","Użyjemy małego sztucznie stworzonego zbioru danych w csv w tym celu."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"komt-G9sLYsI"},"outputs":[],"source":["# np = names_phones\n","np_df = pd.read_csv(f\"{path}mock_names_phones.csv\", header=0, index_col=0)\n","np_df"]},{"cell_type":"markdown","metadata":{"id":"uC2JRqb8LYsJ"},"source":["Ok - dla tego dataframe są 4 zadania:\n","1. Utwórz kolumnę title, która zawiera tytuł każdej osoby (np. Pani, Panna itp.). Ta kolumna powinna być znormalizowana i kategoryczna\n","2. Podziel kolumnę name na kolumnę first name i last name. Obie kolumny powinny mieć pierwszą literę imienia z wielkiej litery\n","3. Usuń wiersz `name`\n","4. Standaryzuj numery telefonów w formacie `00XXXXXXXXX`. To znaczy - dwa zera poprzedzone resztą rzeczywistej liczby\n","\n","Zajmijmy się nimi w kolejności"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9s3lKkrWLYsK"},"outputs":[],"source":["# Najpierw chcemy utworzyć nową kolumnę tytułową, która przyjmuje tytuły grzecznościowe w kolumnie imienia\n","# Aby to uzyskać, musimy podzielić name po białym znaku i wziąć pierwszy element z listy podzielonej\n","example_string = \"this string will be split\"\n","print(example_string.split())\n","print(example_string.split()[0])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lL5XrFl7LYsK"},"outputs":[],"source":["# Aby wykonać operacje na stringach naa kolumnach stringów w pandas, musimy poprzedzić naszą funkcję ciągów znakiem „.str”\n","np_df[\"name\"]\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YziGi6jN2CSm"},"outputs":[],"source":["def capitalize(txt):\n","  return txt.capitalize()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mjPb9PCyLYsL"},"outputs":[],"source":["## Utwórz i wypełnij kolumnę title.\n","# To zadanie można rozwiązać na kilka różnych sposobów.\n","# Zobacz, ile rozwiązań możesz wymyślić\n","np_df[\"title\"] = \n","np_df"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"osnj-IXDLYsM"},"outputs":[],"source":["# Chcemy, aby nasz title był ustandaryzowany i kategoryczny.\n","## Zamień kolumnę na kolumnę kategoryczną i zwróć wszystkie kategorie, które obecnie istnieją w kolumnie\n","np_df[\"title\"] = \n","set(np_df[\"title\"])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"w0-m3r5QLYsN"},"outputs":[],"source":["# Widzimy wiele różnych wariantów. Wybierzmy metodę normalizacji wpisów (np. wielkie litery).\n","## Standaryzuj kolumnę title\n","np_df[\"title\"] = \n","np_df"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"N9aPw9vjLYsO"},"outputs":[],"source":["## W podobny sposób do powyższego utwórz nową kolumnę na imię i jedną na nazwisko.\n","# Upewnij się, że dla obu nowych kolumn nazwy są pisane małymi literami, z wyjątkiem pierwszej litery, która jest pisana wielką literą\n","np_df[\"first_name\"] = \n","np_df[\"last_name\"] = \n","np_df[\"first_name\"] = \n","np_df[\"last_name\"] = \n","\n","np_df"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5A0O47XcLYsP"},"outputs":[],"source":["## Usuń kolumnę name\n","\n","np_df"]},{"cell_type":"markdown","metadata":{"id":"ClHI4914LYsP"},"source":["Świetnie! To prowadzi nas do czwartej części zadania - ujednolicenia numeru telefonu i przekonwertowania go na typ danych int. Przypomnij sobie, jak chcemy, aby nasze numery telefonów wyglądały: zacznij od 00, a następnie do reszty numeru."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-BADJwj1LYsQ","scrolled":true},"outputs":[],"source":["# Zwraca wszystkie (unikalne) numery telefonów, dzięki czemu możemy zobaczyć różne typy problemów jakie nas czekają\n","set(np_df[\"phone number\"])"]},{"cell_type":"markdown","metadata":{"id":"lXoj6f0jLYsQ"},"source":["Ok, więc jakie problemy widzisz?\n","<details>\n","     <summary><b>> Kliknij tutaj, aby zobaczyć problemy</b></summary>\n","     <ul>\n","         <li>Numery zaczynają się różnie – niektóre zaczynają się od `+`, inne od `00`</li>\n","         <li>Niektóre numery mają spacje między grupami liczb, inne są dzielone. Niektóre numery również nie mają „grup”</li>\n","         <li>Niektóre numery zaczynają się od spacji, inne od `+ `, inne od `+`.</li>\n","         <li>Niektóre numery mają tylko cztery liczby</li>\n","     </ul>\n","</details>\n","\n","Istnieje kilka sposobów formatowania tych ciągów do pożądanego wyniku. Tutaj poprowadzę cię przez metodę, w której iterujemy wiersze i stosujemy funkcję, aby ponownie przypisać zmienną. Zacznijmy od stworzenia funkcji pośredniej, która pobiera numer telefonu i manipuluje nim do pożądanego wyniku."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9-42OF7zLYsR"},"outputs":[],"source":["def standardise_phone_number(phone_number):\n","    \n","    ## jeśli pierwszym znakiem jest \"+\", usuń go.\n","    if phone_number.startswith(\"+\"):\n","        phone_number = \n","    \n","    ## usuń wszystkie spacje z numeru telefonu\n","    phone_number = \n","\n","    ## usuń myślniki z numeru telefonu\n","    phone_number = \n","    \n","    ## jeśli numer nie zaczyna się od 00, dodaj 00 do początku numeru\n","    \n","    \n","    ## zwróć numer telefonu\n","    return phone_number"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"S7Yitmh9LYsR"},"outputs":[],"source":["# Będziemy iterować po wierszach ramki danych i ponownie przypiszemy wiersz do standardowego wariantu\n","for index, row in np_df.iterrows():\n","    \n","    ## Odwołaj się do naszej funkcji standaryzacji na numer telefonu dla bieżącej pętli\n","    row[\"phone number\"] = \n","    \n","np_df"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"z-bqj0eTLYsS"},"outputs":[],"source":["# W naszej ramce danych nadal znajdują się nieprawidłowe liczby (tj. te, które pierwotnie miały długość 4)\n","## Zamień wszystkie numery telefonów poniżej 10 cyfr/znaków na pd.NA\n","# Podpowiedź: będzie potrzebna metoda .loc\n","np_df\n","np_df"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zHNZ3iqiLYsS"},"outputs":[],"source":["# Skoncentrujemy się na brakujących danych w następnej części, ale policzmy liczbę wierszy z NA i usuńmy je\n","null_phone_numbers = \n","print(\"Number of null phone numbers:\", null_phone_numbers.sum())\n","\n","# Usuń wiersze, które mają puste numery telefonów\n","np_df = np_df.dropna(subset=[\"phone number\"])\n","np_df"]},{"cell_type":"markdown","metadata":{"id":"fTHEVefALYsT"},"source":["Bardziej skomplikowane manipulacje ciągami znaków można wykonać za pomocą **wyrażeń regularnych**, znanych również jako [regex](https://docs.python.org/3/howto/regex.html). Nie będziemy tutaj przyglądać się wyrażeniu regularnemu, ale ważne jest, aby wiedzieć o jego mocy. Zasadniczo wyrażenie regularne pozwala nam określić reguły dla ciągów, które chcemy dopasować. Ma bardzo szerokie zastosowanie. Oto kilka przykładów:\n","- identyfikuj wiadomości e-mail w zakresach tekstu\n","- sprawdź, czy adres URL ma poprawny format\n","- wyodrębnij tylko cyfry z ciągu tekstowego\n","\n","Kiedy natkniesz się na zadania, które wymagają oczyszczenia danych tekstowych, regex jest narzędziem do tego zadania."]},{"cell_type":"markdown","metadata":{"id":"8ZPP2j-VLYsT"},"source":["## Scalanie danych razem (merging)\n","\n","Czasami znajdziemy dane w różnych plikach, które musimy połączyć w jedną ramkę danych, zanim będziemy mogli jej użyć. Przykładem tego są [dane IMDB](http://www.imdb.com/interfaces#plain) – gdzie, być może ze względu na rozmiar dostępnych danych, twórcy postanowili podzielić cały zbiór danych na wiele osobnych plików. Przyjrzyjmy się szybko, jak możemy połączyć dane z tych wielu plików.\n","\n","Źródło: \n","IMDb\n","(http://www.imdb.com).\n","\n","Pliki do pobrania i scalenia to:\n","- tytuł.akas.tsv.gz\n","- tytuł.podstawy.tsv.gz\n","- tytuł.oceny.tsv.gz"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Vc6VBzZJLYsT"},"outputs":[],"source":["# URUCHOM TĘ KOMÓRKĘ TYLKO JEŚLI CHCESZ PONOWNIE POBRAĆ CAŁE DANE\n","import requests\n","import gzip\n","import pandas as pd\n","import pickle\n","import os\n","\n","DATA_FOLDER = \"DATA\" # TODO: najpierw ten folder trzeba utworzyc\n","DOWNLOAD_URL = \"https://datasets.imdbws.com/\"\n","files_to_download = [\"title.ratings.tsv.gz\", \"title.akas.tsv.gz\", \"title.basics.tsv.gz\"]\n","\n","\n","for file_string in files_to_download:\n","    # pobierz plik tsv.gz\n","    # plik jest obiektem request\n","    print(\"Getting request for file:\", file_string)\n","    df = pd.read_csv(DOWNLOAD_URL + file_string, sep=\"\\t\", compression=\"gzip\")\n","    df = df.iloc[-10000:]\n","    print(df.shape)\n","    pickle.dump(df, open(os.path.join(DATA_FOLDER, file_string.replace(\".tsv.gz\", \".df\")), \"wb\"))\n","    print(df.head())\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qPVse_kYLYsU"},"outputs":[],"source":["ratings_df = pickle.load(open(os.path.join(DATA_FOLDER, \"title.ratings.df\"), \"rb\"))\n","films_df = pickle.load(open(os.path.join(DATA_FOLDER, \"title.akas.df\"), \"rb\"))\n","basics_df = pickle.load(open(os.path.join(DATA_FOLDER, \"title.basics.df\"), \"rb\"))"]},{"cell_type":"markdown","metadata":{"id":"xSD5qFqrLYsU"},"source":["### Łączenie wielu ramek danych\n","\n","Podobnie jak w SQL, chcemy wykonać jakiś rodzaj [`.join()`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.join.html) lub [ `.merge()`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.merge.html#pandas.DataFrame.merge) przez ramki danych, które obecnie posiadamy. Wymaga to ustawienia unikalnego identyfikatora/klucza podstawowego jako indeksu ramek danych. Pamiętaj o dwóch głównych typach złączeń,  **inner** i **lefyt**. Jak myślisz, które podejście będzie bardziej poprawne w tym przypadku?"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3ZX6IVU_LYsV"},"outputs":[],"source":["## zmodyfikuj indeksy ratings_df, basics_df i movies_df, aby wszystkie miały wspólny indeks\n","ratings_df = \n","basics_df = \n","films_df = \n","films_df.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9aNVfICALYsV"},"outputs":[],"source":["## Wykonaj join lub merge z basics_df i ratings_df za pomocą movies_df\n","df = \n","df"]},{"cell_type":"markdown","metadata":{"id":"hnxwaHdwgmuJ"},"source":["---"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.18"}},"nbformat":4,"nbformat_minor":0}
